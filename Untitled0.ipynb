{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Donald724276/AI-CW/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LTk1Bd5PhwX"
      },
      "outputs": [],
      "source": [
        "# 1. Data Setup\n",
        "import os\n",
        "\n",
        "!pip install -q --upgrade kaggle\n",
        "os.environ['KAGGLE_API_TOKEN'] = 'KGAT_fcee887368797d3cfb1d56d035c130fe'\n",
        "!kaggle datasets download -d xhlulu/140k-real-and-fake-faces\n",
        "!unzip -q 140k-real-and-fake-faces.zip -d dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Data Loader and Preprocessing\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "# Parameters\n",
        "img_size = (224,224) # Dimension required by ResNet50\n",
        "batch_size = 64\n",
        "\n",
        "# Generator with Augmentation: Creates \"new\" images by working on an image\n",
        "# to prevent the model from memorizing certain photos\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range = 20,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        ")\n",
        "\n",
        "# Data Loading\n",
        "base_dir = 'dataset/real_vs_fake/real-vs-fake'\n",
        "\n",
        "# Loads Training Data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir + '/train',\n",
        "    target_size = img_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary',\n",
        ")\n",
        "\n",
        "# Loads Validation Data\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    base_dir + '/valid',\n",
        "    target_size = img_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary',\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "# Generates and Loads Test Data\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_dir = base_dir + '/test'\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "# Generates Confusion Matrix Data\n",
        "cfm_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "ENZwxJSbP_fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Model Architecture\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "# Intialise ResNet50 Architecture as Base Model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224,3))\n",
        "base_model.trainable = False\n",
        "\n",
        "# Custom Classification Layers\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "Ds0LQ9URS4-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Model Training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data = val_generator,\n",
        "    epochs = 5\n",
        ")"
      ],
      "metadata": {
        "id": "WUDukZFBbm2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Fine Tuning\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:140]:\n",
        "  layers.trainable = False\n",
        "\n",
        "model.compile(optimizer = optimizers.Adam(learning_rate=0.00001),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    validation_data = val_generator,\n",
        "    epochs = 5\n",
        ")"
      ],
      "metadata": {
        "id": "8eTbJf07fHM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.1 Graph Visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Accuracy Graph\n",
        "plt.figure(figsize = (10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history_fine.history['accuracy'], label = 'Training Acc')\n",
        "plt.plot(history_fine.history['val_accuracy'], label = 'Validation Acc')\n",
        "plt.title('Model Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Loss Graph\n",
        "plt.figure(figsize = (10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history_fine.history['loss'], label = 'Training Loss')\n",
        "plt.plot(history_fine.history['val_loss'], label = 'Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z3Jzb-k9bww8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.2 Prediction Visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "imgs, labels = next(test_generator)\n",
        "predictions = model.predict(imgs)\n",
        "\n",
        "plt.figure(figsize = (15,8))\n",
        "for i in range(10):\n",
        "  plt.subplot(2,5,i+1)\n",
        "  plt.imshow(imgs[i])\n",
        "\n",
        "  # Undo ResNet Preprocessing [Fix the colors(BGR --> RGB)]\n",
        "  disp_img = imgs[i]\n",
        "  disp_img[:,:,0] += 103.939\n",
        "  disp_img[:,:,1] += 116.779\n",
        "  disp_img[:,:,2] += 123.68\n",
        "  disp_img = disp_img[:,:,::-1]\n",
        "  disp_img = np.clip(disp_img, 0, 255).astype('uint8')\n",
        "\n",
        "  plt.imshow(disp_img)\n",
        "\n",
        "  score = predictions[i][0]\n",
        "  pred_label = \"FAKE\" if score > 0.5 else \"REAL\"\n",
        "  actual_label = \"FAKE\" if labels[i] == 1 else \"REAL\"\n",
        "\n",
        "  col = 'green' if pred_label == actual_label else 'red'\n",
        "  plt.title(f\"Pred: {pred_label}\\n({score:.2f})\", color=col)\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eupHIf14S2Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Confusion Matrix\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get Predictions\n",
        "preds = model.predict(cfm_generator)\n",
        "\n",
        "# Convert to 0s and 1s\n",
        "predictions = (preds > 0.5).astype(int)\n",
        "\n",
        "# Get the Answer Key\n",
        "correct_answers = test_generator.classes\n",
        "\n",
        "# Draw the Confusion Matrix\n",
        "cm = confusion_matrix(correct_answers, predictions)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Real', 'Fake'],\n",
        "            yticklabels=['Real', 'Fake'])\n",
        "plt.title('Confusion Matrix (Test Set)')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n",
        "# 5. Print the Statistics\n",
        "print(classification_report(correct_answers, predictions, target_names=['Real', 'Fake']))"
      ],
      "metadata": {
        "id": "Ux3T2QiXjw4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Reload/Upload weights\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "model = load_model(filename)\n"
      ],
      "metadata": {
        "id": "bFT9tqvakL-k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}